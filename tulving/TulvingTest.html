<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
"http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en">
<head>
<!-- 2024-02-22 jeu. 19:35 -->
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<title>Memory GAPS: Would LLM pass the Tulving Test?</title>
<meta name="author" content="J.-M. Chauvet" />
<meta name="generator" content="Org Mode" />
<style>
  #content { max-width: 60em; margin: auto; }
  .title  { text-align: center;
             margin-bottom: .2em; }
  .subtitle { text-align: center;
              font-size: medium;
              font-weight: bold;
              margin-top:0; }
  .todo   { font-family: monospace; color: red; }
  .done   { font-family: monospace; color: green; }
  .priority { font-family: monospace; color: orange; }
  .tag    { background-color: #eee; font-family: monospace;
            padding: 2px; font-size: 80%; font-weight: normal; }
  .timestamp { color: #bebebe; }
  .timestamp-kwd { color: #5f9ea0; }
  .org-right  { margin-left: auto; margin-right: 0px;  text-align: right; }
  .org-left   { margin-left: 0px;  margin-right: auto; text-align: left; }
  .org-center { margin-left: auto; margin-right: auto; text-align: center; }
  .underline { text-decoration: underline; }
  #postamble p, #preamble p { font-size: 90%; margin: .2em; }
  p.verse { margin-left: 3%; }
  pre {
    border: 1px solid #e6e6e6;
    border-radius: 3px;
    background-color: #f2f2f2;
    padding: 8pt;
    font-family: monospace;
    overflow: auto;
    margin: 1.2em;
  }
  pre.src {
    position: relative;
    overflow: auto;
  }
  pre.src:before {
    display: none;
    position: absolute;
    top: -8px;
    right: 12px;
    padding: 3px;
    color: #555;
    background-color: #f2f2f299;
  }
  pre.src:hover:before { display: inline; margin-top: 14px;}
  /* Languages per Org manual */
  pre.src-asymptote:before { content: 'Asymptote'; }
  pre.src-awk:before { content: 'Awk'; }
  pre.src-authinfo::before { content: 'Authinfo'; }
  pre.src-C:before { content: 'C'; }
  /* pre.src-C++ doesn't work in CSS */
  pre.src-clojure:before { content: 'Clojure'; }
  pre.src-css:before { content: 'CSS'; }
  pre.src-D:before { content: 'D'; }
  pre.src-ditaa:before { content: 'ditaa'; }
  pre.src-dot:before { content: 'Graphviz'; }
  pre.src-calc:before { content: 'Emacs Calc'; }
  pre.src-emacs-lisp:before { content: 'Emacs Lisp'; }
  pre.src-fortran:before { content: 'Fortran'; }
  pre.src-gnuplot:before { content: 'gnuplot'; }
  pre.src-haskell:before { content: 'Haskell'; }
  pre.src-hledger:before { content: 'hledger'; }
  pre.src-java:before { content: 'Java'; }
  pre.src-js:before { content: 'Javascript'; }
  pre.src-latex:before { content: 'LaTeX'; }
  pre.src-ledger:before { content: 'Ledger'; }
  pre.src-lisp:before { content: 'Lisp'; }
  pre.src-lilypond:before { content: 'Lilypond'; }
  pre.src-lua:before { content: 'Lua'; }
  pre.src-matlab:before { content: 'MATLAB'; }
  pre.src-mscgen:before { content: 'Mscgen'; }
  pre.src-ocaml:before { content: 'Objective Caml'; }
  pre.src-octave:before { content: 'Octave'; }
  pre.src-org:before { content: 'Org mode'; }
  pre.src-oz:before { content: 'OZ'; }
  pre.src-plantuml:before { content: 'Plantuml'; }
  pre.src-processing:before { content: 'Processing.js'; }
  pre.src-python:before { content: 'Python'; }
  pre.src-R:before { content: 'R'; }
  pre.src-ruby:before { content: 'Ruby'; }
  pre.src-sass:before { content: 'Sass'; }
  pre.src-scheme:before { content: 'Scheme'; }
  pre.src-screen:before { content: 'Gnu Screen'; }
  pre.src-sed:before { content: 'Sed'; }
  pre.src-sh:before { content: 'shell'; }
  pre.src-sql:before { content: 'SQL'; }
  pre.src-sqlite:before { content: 'SQLite'; }
  /* additional languages in org.el's org-babel-load-languages alist */
  pre.src-forth:before { content: 'Forth'; }
  pre.src-io:before { content: 'IO'; }
  pre.src-J:before { content: 'J'; }
  pre.src-makefile:before { content: 'Makefile'; }
  pre.src-maxima:before { content: 'Maxima'; }
  pre.src-perl:before { content: 'Perl'; }
  pre.src-picolisp:before { content: 'Pico Lisp'; }
  pre.src-scala:before { content: 'Scala'; }
  pre.src-shell:before { content: 'Shell Script'; }
  pre.src-ebnf2ps:before { content: 'ebfn2ps'; }
  /* additional language identifiers per "defun org-babel-execute"
       in ob-*.el */
  pre.src-cpp:before  { content: 'C++'; }
  pre.src-abc:before  { content: 'ABC'; }
  pre.src-coq:before  { content: 'Coq'; }
  pre.src-groovy:before  { content: 'Groovy'; }
  /* additional language identifiers from org-babel-shell-names in
     ob-shell.el: ob-shell is the only babel language using a lambda to put
     the execution function name together. */
  pre.src-bash:before  { content: 'bash'; }
  pre.src-csh:before  { content: 'csh'; }
  pre.src-ash:before  { content: 'ash'; }
  pre.src-dash:before  { content: 'dash'; }
  pre.src-ksh:before  { content: 'ksh'; }
  pre.src-mksh:before  { content: 'mksh'; }
  pre.src-posh:before  { content: 'posh'; }
  /* Additional Emacs modes also supported by the LaTeX listings package */
  pre.src-ada:before { content: 'Ada'; }
  pre.src-asm:before { content: 'Assembler'; }
  pre.src-caml:before { content: 'Caml'; }
  pre.src-delphi:before { content: 'Delphi'; }
  pre.src-html:before { content: 'HTML'; }
  pre.src-idl:before { content: 'IDL'; }
  pre.src-mercury:before { content: 'Mercury'; }
  pre.src-metapost:before { content: 'MetaPost'; }
  pre.src-modula-2:before { content: 'Modula-2'; }
  pre.src-pascal:before { content: 'Pascal'; }
  pre.src-ps:before { content: 'PostScript'; }
  pre.src-prolog:before { content: 'Prolog'; }
  pre.src-simula:before { content: 'Simula'; }
  pre.src-tcl:before { content: 'tcl'; }
  pre.src-tex:before { content: 'TeX'; }
  pre.src-plain-tex:before { content: 'Plain TeX'; }
  pre.src-verilog:before { content: 'Verilog'; }
  pre.src-vhdl:before { content: 'VHDL'; }
  pre.src-xml:before { content: 'XML'; }
  pre.src-nxml:before { content: 'XML'; }
  /* add a generic configuration mode; LaTeX export needs an additional
     (add-to-list 'org-latex-listings-langs '(conf " ")) in .emacs */
  pre.src-conf:before { content: 'Configuration File'; }

  table { border-collapse:collapse; }
  caption.t-above { caption-side: top; }
  caption.t-bottom { caption-side: bottom; }
  td, th { vertical-align:top;  }
  th.org-right  { text-align: center;  }
  th.org-left   { text-align: center;   }
  th.org-center { text-align: center; }
  td.org-right  { text-align: right;  }
  td.org-left   { text-align: left;   }
  td.org-center { text-align: center; }
  dt { font-weight: bold; }
  .footpara { display: inline; }
  .footdef  { margin-bottom: 1em; }
  .figure { padding: 1em; }
  .figure p { text-align: center; }
  .equation-container {
    display: table;
    text-align: center;
    width: 100%;
  }
  .equation {
    vertical-align: middle;
  }
  .equation-label {
    display: table-cell;
    text-align: right;
    vertical-align: middle;
  }
  .inlinetask {
    padding: 10px;
    border: 2px solid gray;
    margin: 10px;
    background: #ffffcc;
  }
  #org-div-home-and-up
   { text-align: right; font-size: 70%; white-space: nowrap; }
  textarea { overflow-x: auto; }
  .linenr { font-size: smaller }
  .code-highlighted { background-color: #ffff00; }
  .org-info-js_info-navigation { border-style: none; }
  #org-info-js_console-label
    { font-size: 10px; font-weight: bold; white-space: nowrap; }
  .org-info-js_search-highlight
    { background-color: #ffff00; color: #000000; font-weight: bold; }
  .org-svg { }
</style>
<script src="https://unpkg.com/@popperjs/core@2"></script>
<script src="https://unpkg.com/tippy.js@6"></script>
<link href="https://fonts.googleapis.com/css?family=EB+Garamond" rel="stylesheet">
<link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/tonsky/FiraCode@4/distr/fira_code.css">
<style>table.ref td{ text-align: right; font-size: small; font-family:'Fira Code', monospace; }</style>
<style>table.center { margin-left:auto; margin-right:auto; }</style>
<style>img.center { margin-left:auto; margin-right:auto; }</style>
<style>.source-code { text-align: left; font-size: small; font-family:'Fira Code', monospace; }</style>
<style>pre { text-align: left; font-size: small; font-family:'Fira Code', monospace; }</style>
<style>body { font-family:'EB Garamond', serif; font-size: 16px; }</style>
<style>blockquote {background: #f9f9f9; border-left: 10px solid #ccc; margin: 1.5em 10px; padding: 0.5em 10px; quotes: "\201C""\201D""\2018""\2019";} blockquote:before {color: #ccc; content: open-quote; font-size: 4em; line-height: 0.1em; margin-right: 0.25em; vertical-align: -0.4em;} blockquote p {display: inline;}</style>
<style>.figure p:nth-child(2) {text-align: justify; text-justify: inter-word;}</style>
<style>table caption {text-align: justify; text-justify: inter-word;}</style>
</head>
<body>
<div id="content" class="content">
<h1 class="title">Memory GAPS: Would LLM pass the Tulving Test?</h1>

<div id="outline-container-org6bfeed4" class="outline-2">
<h2 id="org6bfeed4">Abstract</h2>
</div>
<div id="outline-container-org2d02980" class="outline-2">
<h2 id="org2d02980">Introduction</h2>
<div class="outline-text-2" id="text-org2d02980">
<p>
In his groundbreaking studies of memory, Endel Tulving (1927-2023) noted that &ldquo;one of the most compelling and salient characteristics of remembering of past events is the individual&rsquo;s subjective awareness of remembering&rdquo; <a href="#citeproc_bib_item_1">[1]</a>. In order to include the rememberer&rsquo;s recollective experience into the critical constructs in the conceptualization of remembering, Tulving suggested an &ldquo;overall pretheoretical framework&rdquo;, called the <i>General Abstract Processing System</i> or GAPS. This paper investigates whether the GAPS also provides insights when the subject is no longer human but a Large Language Model (LLM).
</p>

<p>
Tulving championed the distinction of <i>episodic</i> from <i>semantic</i> memory, successfully arguing that being functionally different, they represent separate but related systems. Both are placed on the same side of the cognitive division between <i>declarative memory</i> (as episodic and semantic information can be expressed through language&#x2013;e.g. repairing a bicycle) on the one hand, and <i>skills</i> (which can be observed only in behavior&#x2013;e.g. riding a bicycle) on the other.
</p>
</div>

<div id="outline-container-org33c343d" class="outline-3">
<h3 id="org33c343d">The GAPS and the Transformer</h3>
<div class="outline-text-3" id="text-org33c343d">
<p>
In Tulving&rsquo;s framework, a single act of remembering forms the unit of human episodic memory. Remembering is a process that begins with the witnessing or experiencing of an episode and ends with its recollective experience or with the conversion of the remembered information into some other form, or both. The GAPS specifies so called <i>elements</i> of remembering and their interrelations in order to decompose this process.
</p>

<p>
The GAPS distinguishes two kinds of elements: observable events and hypothetical constructs (processes and states); and it divides elements into two categories: elements of encoding and elements of retrieval.
</p>


<div id="orge822aa0" class="figure">
<p><img src="ElementsOfRemembering-rev.png" alt="ElementsOfRemembering-rev.png" width="500px" />
</p>
<p><span class="figure-number">Figure 1: </span><b>The GAPS: Elements of Episodic Memory and their Relations.</b> The element of encoding is a process that converts the information about an experienced event or episode (in a particular setting, at a particular time) into an <i>engram</i> or memory trace. The central element of the retrieval processes <i>ecphoric</i> information, a synergistic product of the engram and the retrieval cue, which calls on both episodic and semantic information. Source for figure: Ch. 7, <a href="#citeproc_bib_item_1">[1, 7-1, p. 135]</a>.</p>
</div>

<p>
Of particular interest to this study of applicability of the GAPS framework to LLM are the possible transpositions of engram and ecphoric information into the domain of generative AI. In his seminal book, Tulving offers a very broad definition of engrams: &ldquo;the product of encoding&rdquo;, &ldquo;conditions for recollection of the experienced event&rdquo;, or &ldquo;differences between the state of the memory system before and after encoding&rdquo;. The latter is closely related the original definitions of these terms introduced by Richard Semon (1859&#x2013;1918): &ldquo;to represent the enduring changes brought about by the energetic effect of stimuli in the organism&rdquo; <a href="#citeproc_bib_item_2">[2]</a>, <a href="#citeproc_bib_item_3">[3]</a>. Note that if, in both clarifications, the nature of the changes are unknown, the term became nonetheless broadly known in psychology research through the later work of Karl Lashley (1890&#x2013;1958) concluding, amongst other experimental results on neural mechanisms involved in learning and memory, that &ldquo;there is no demonstrable localization of memory trace&rdquo; <a href="#citeproc_bib_item_4">[4]</a>.
</p>

<p>
Similarly inspired by Semon, Tulving suggested the terms <i>ecphory</i> and <i>ecphoric information</i> to designate respectively the process that brings (i) the relevant information in the retrieval environment into interaction with (ii) the original or recoded engram, and the output of this process. Such ecphoric information determines the particulars of recollective experience in the next phase of remembering: <i>conversion</i>. In the GAPS model, ecphoric information is basically a task-free component of the retrieval process, it is simply used by being converted into another form in the memory performance.
</p>

<p>
The categories of encoding and retrieval in the GAPS are not without analogies with the <i>Transformer</i> architecture of neural networks at the core of LLMs, which precisely articulates encoders and decoders to process vector embeddings representing words and sentences.
</p>


<div id="org7db414f" class="figure">
<p><img src="Transformer.png" alt="Transformer.png" width="500px" />
</p>
<p><span class="figure-number">Figure 2: </span><b>The Transformer Architecture.</b> Based on the 2017 paper <a href="#citeproc_bib_item_5">[5]</a> attention mechanism, the Transformer architecture requires less training time than previous recurrent neural architectures. Input text is split into tokens (sometimes called <i>n-gram</i>, dangerously reminiscent of Semon&rsquo;s engrams&#x2013;see text), then converted into vectors. Through different layers, each token is contextualized with other tokens via parallel attention heads, calculating weights for each according to its importance. The Transformer Architecture elaborates on <i>softmax-based</i> attention mechanism <a href="#citeproc_bib_item_6">[6]</a> and <i>Fast Weight Controllers</i> <a href="#citeproc_bib_item_7">[7]</a>. Source for figure: <a href="#citeproc_bib_item_5">[5]</a>.</p>
</div>

<p>
At this stage, from cursorily reviewing the architecture of both GAPS and Transformer&#x2013;and keeping in mind that Tulving&rsquo;s psychological framework is only &ldquo;pre-theoretical&rdquo; and &ldquo;highly schematic&rdquo;, while Transformers are actual computer implementations&#x2013;the practical analogy would unfold as follows:
</p>

<table id="org0be1005" border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">
<caption class="t-above"><span class="table-number">Table 1:</span> <b>Hypothetical analogy between GAPS and Transformer.</b> Semantic memory, in Tulving&rsquo;s acception, would be represented by the probability distribution learned by the LLM during the pretraining phase. In Transformers it determines the particulars of the output based on the input (prompt).</caption>

<colgroup>
<col  class="org-left" />

<col  class="org-left" />

<col  class="org-left" />
</colgroup>
<thead>
<tr>
<th scope="col" class="org-left">&#xa0;</th>
<th scope="col" class="org-left">GAPS</th>
<th scope="col" class="org-left">Transformer</th>
</tr>
</thead>
<tbody>
<tr>
<td class="org-left">Processes</td>
<td class="org-left">encoding</td>
<td class="org-left">encoder</td>
</tr>

<tr>
<td class="org-left">&#xa0;</td>
<td class="org-left">recoding</td>
<td class="org-left">encoder</td>
</tr>

<tr>
<td class="org-left">&#xa0;</td>
<td class="org-left">ecphory</td>
<td class="org-left">encoder</td>
</tr>

<tr>
<td class="org-left">&#xa0;</td>
<td class="org-left">conversion</td>
<td class="org-left">decoder</td>
</tr>
</tbody>
<tbody>
<tr>
<td class="org-left">States</td>
<td class="org-left">engram</td>
<td class="org-left">vector embedding</td>
</tr>

<tr>
<td class="org-left">&#xa0;</td>
<td class="org-left">ecphoric information</td>
<td class="org-left">output probabilities</td>
</tr>

<tr>
<td class="org-left">&#xa0;</td>
<td class="org-left">memory performance</td>
<td class="org-left">output</td>
</tr>
</tbody>
</table>
</div>
</div>

<div id="outline-container-orgc7950e1" class="outline-3">
<h3 id="orgc7950e1">Tulving&rsquo;s &ldquo;direct comparison&rdquo;: recognition versus recall</h3>
<div class="outline-text-3" id="text-orgc7950e1">
<p>
In order to further investigate the analogy and its grounds, we adopt Tulving&rsquo;s design of &ldquo;direct comparison&rdquo; experiments to assess recognition versus recall tasks in LLMs. Recognition and recall are both processes of retrieval and both result in the rememberer&rsquo;s awareness of a past event. The simple episodes in the experiment are to be presentations of a list of English words to be remembered. In this simplified situation of comparing recognition and recall tasks, we consider only two independent dimensions: one has to do with the type of retrieval information, or <i>cue</i>, available to the rememberer; the second refers to the conversion process in the GAPS framework. The retrieval information includes copies of the studied words and non-copy cue words. As for the conversion process: in the recognition task, the rememberer has to express whether or not the cue word was in the study list (<i>familiarity</i>); in the recall task, the rememberer has to identify a word in the study list, if any, associated with the cue word (<i>identification</i>), thereby expressing some other aspect of the original memorizing experience. Note that in the GAPS framework, the first dimension involves processes anterior to the construction of ecphoric information, while the second relates to post-ecphoric processes. The experimental results are therefore captured by the 2 x 2 matrix in Table <a href="#org543e4e7">2</a>
</p>

<table id="org543e4e7" border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">
<caption class="t-above"><span class="table-number">Table 2:</span> Differences between recognition and recall tasks. Source for table: Ch. <a href="#citeproc_bib_item_1">[1, p. 14]</a>.</caption>

<colgroup>
<col  class="org-left" />

<col  class="org-left" />

<col  class="org-left" />
</colgroup>
<thead>
<tr>
<th scope="col" class="org-left">Retrieval information</th>
<th scope="col" class="org-left">Conversion</th>
<th scope="col" class="org-left">&#xa0;</th>
</tr>

<tr>
<th scope="col" class="org-left">&#xa0;</th>
<th scope="col" class="org-left">Familiarity</th>
<th scope="col" class="org-left">Identification</th>
</tr>
</thead>
<tbody>
<tr>
<td class="org-left">Copy Cue Word</td>
<td class="org-left"><i>Recognition</i></td>
<td class="org-left"><i>?</i></td>
</tr>

<tr>
<td class="org-left">Non-Copy Cue Word</td>
<td class="org-left"><i>?</i></td>
<td class="org-left"><i>Recall</i></td>
</tr>
</tbody>
</table>

<p>
Conventional recognition and recall tests sit in two of the four cells in the matrix. When the rememberer, however, declares a cue other than a copy cue word to be familiar it is a <i>false positive</i> response from the conventional perspective although psychologists might disagree on how to think about such responses <a href="#citeproc_bib_item_8">[8]</a>. The other empty cell represents a situation where the rememberer&rsquo;s somewhat strange task is to repeat the cue word to confirm it is associated with the copy in the study list. <i>False negatives</i> are of interest here and Tulving&rsquo;s interpretation was that these entailed a form of continuity between recognition and recall retrieval processes.
</p>

<p>
The direct comparison test design represents all four cells of the matrix. In a typical session the LLM is prompted to memorize a list of 48 common english words. In a group of experiments, the LLM is prompted with a cue word and asked whether the cue is included or not in the studied list; in another group, the LLM is prompted with a cue word and asked to retrieve any strongly associated word in the studied list (or none if no such word is evoked by the cue).
</p>

<p>
In each experiment 32 cue words are presented in the 32 prompts: eight of these cue words were identical with eight words in the list (<i>copy cues</i>), eight were strongly associated words (<i>non-copy associated</i> cues), eight were rhyming words (<i>non copy rhymes</i> cues), and eight were unrelated distractors (<i>non-copy unrelated</i> cues). The 32 cue words are identical for both the recognition and the recall task.
</p>

<p>
In order to introduce the distinction between immediate and delayed retrieval of the original experimental design, the experiment is run twice for each group: in the first run, memorization and retrieval are both in each individual prompt (immediate); in the second, memorization is the first prompt of a conversation (chat) with the LLM, followed by retrieval prompts which continue the conversation (delayed).
</p>
</div>
</div>
</div>

<div id="outline-container-org30a5ac9" class="outline-2">
<h2 id="org30a5ac9">Results</h2>
<div class="outline-text-2" id="text-org30a5ac9">
<p>
As a reference benchmark, the results of Tulving&rsquo;s original experiments are presented in Table <a href="#org6eb9db7">3</a> from Ch. <a href="#citeproc_bib_item_1">[1, p. 14, Table 14.2]</a>:
</p>

<table id="org6eb9db7" border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">
<caption class="t-above"><span class="table-number">Table 3:</span> <b>Summary of memory performance in the original direct comparison experiment.</b> Each proportion shown is based on 576 observations. The data for the familiarity (recognition) task show proportion of cases in which the human subjects regarder the cue word as included in the list. Hence the data for copy cues represent &rsquo;correct&rsquo; responses, whereas the data from the other three types of cues represent &rsquo;false positives&rsquo;. The data for the indetification (recall) task indicate proportions of responses to the cue being any target word in the list.</caption>

<colgroup>
<col  class="org-left" />
</colgroup>

<colgroup>
<col  class="org-right" />

<col  class="org-right" />
</colgroup>

<colgroup>
<col  class="org-right" />

<col  class="org-right" />
</colgroup>
<thead>
<tr>
<th scope="col" class="org-left">Retrieval information</th>
<th scope="col" class="org-right">Conversion</th>
<th scope="col" class="org-right">&#xa0;</th>
<th scope="col" class="org-right">&#xa0;</th>
<th scope="col" class="org-right">&#xa0;</th>
</tr>

<tr>
<th scope="col" class="org-left">&#xa0;</th>
<th scope="col" class="org-right">Familiarity</th>
<th scope="col" class="org-right">&#xa0;</th>
<th scope="col" class="org-right">Identification</th>
<th scope="col" class="org-right">&#xa0;</th>
</tr>

<tr>
<th scope="col" class="org-left">&#xa0;</th>
<th scope="col" class="org-right">Immediate</th>
<th scope="col" class="org-right">Delayed</th>
<th scope="col" class="org-right">Immediate</th>
<th scope="col" class="org-right">Delayed</th>
</tr>
</thead>
<tbody>
<tr>
<td class="org-left">Copy Cue Word</td>
<td class="org-right">0.78</td>
<td class="org-right">0.71</td>
<td class="org-right">0.69</td>
<td class="org-right">0.60</td>
</tr>

<tr>
<td class="org-left">Non-Copy Associated</td>
<td class="org-right">0.15</td>
<td class="org-right">0.20</td>
<td class="org-right">0.54</td>
<td class="org-right">0.37</td>
</tr>

<tr>
<td class="org-left">Non-copy Rhyme</td>
<td class="org-right">0.09</td>
<td class="org-right">0.15</td>
<td class="org-right">0.20</td>
<td class="org-right">0.31</td>
</tr>

<tr>
<td class="org-left">Non-copy Unrelated</td>
<td class="org-right">0.08</td>
<td class="org-right">0.18</td>
<td class="org-right">0.04</td>
<td class="org-right">0.02</td>
</tr>
</tbody>
</table>


<p>
The memory performance of LLMs in the Tulving Test of direct comparison is presented along the same format in Table <a href="#org77d14fe">4</a>.
</p>

<table id="org77d14fe" border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">
<caption class="t-above"><span class="table-number">Table 4:</span> <b>Summary of memory performance of the <code>mistral-7b-instruct-v0</code> LLM in the direct comparison experiment.</b> Each proportion is based on 384 observations (but see text). Interpretations of proportions are the same as above Table <a href="#org6eb9db7">3</a>.</caption>

<colgroup>
<col  class="org-left" />
</colgroup>

<colgroup>
<col  class="org-right" />

<col  class="org-right" />
</colgroup>

<colgroup>
<col  class="org-right" />

<col  class="org-right" />
</colgroup>
<thead>
<tr>
<th scope="col" class="org-left">Retrieval information</th>
<th scope="col" class="org-right">Conversion</th>
<th scope="col" class="org-right">&#xa0;</th>
<th scope="col" class="org-right">&#xa0;</th>
<th scope="col" class="org-right">&#xa0;</th>
</tr>

<tr>
<th scope="col" class="org-left">&#xa0;</th>
<th scope="col" class="org-right">Familiarity</th>
<th scope="col" class="org-right">&#xa0;</th>
<th scope="col" class="org-right">Identification</th>
<th scope="col" class="org-right">&#xa0;</th>
</tr>

<tr>
<th scope="col" class="org-left">&#xa0;</th>
<th scope="col" class="org-right">Immediate</th>
<th scope="col" class="org-right">Delayed</th>
<th scope="col" class="org-right">Immediate</th>
<th scope="col" class="org-right">Delayed</th>
</tr>
</thead>
<tbody>
<tr>
<td class="org-left">Copy Cue Word</td>
<td class="org-right">1</td>
<td class="org-right">0.46</td>
<td class="org-right">0.46</td>
<td class="org-right">0</td>
</tr>

<tr>
<td class="org-left">Non-Copy Associated</td>
<td class="org-right">0</td>
<td class="org-right">0.47</td>
<td class="org-right">0.49</td>
<td class="org-right">0.40</td>
</tr>

<tr>
<td class="org-left">Non-copy Rhyme</td>
<td class="org-right">0</td>
<td class="org-right">0.50</td>
<td class="org-right">0.18</td>
<td class="org-right">0.01</td>
</tr>

<tr>
<td class="org-left">Non-copy Unrelated</td>
<td class="org-right">0</td>
<td class="org-right">0.41</td>
<td class="org-right">0.08</td>
<td class="org-right">0</td>
</tr>
</tbody>
</table>

<p>
Within each result table, several comparisons are of interest. First the probability that copy cues were familiar was higher than the probability of identification and production of the target word in response to the copy cue, in both the human (Table <a href="#org6eb9db7">3</a>) and the  LLM (Table <a href="#org77d14fe">4</a>) subject&#x2013;here <code>mistral-7b-instruct-v0</code>. Second, the probability that extra-list unrelated cues were (incorrectly) recognized as members of the memorized list increased from the immediate to delayed test, in both human and LLM subjects. Remarkably and contrasting with the human subject, in the immediate recognition task the LLM never erred: no false positives for non-copy cues and 100% familiarity for copy cues. Third, rhyme words proved in both cases more effective than unrelated distractor cues in recall. Fourth, strongly associated cues were considered members of the list with much higher probability in the immediate test, the difference being greatly reduced in the delayed test. The case of the LLM subject varies a bit, since no false positives are produced in the immediate recognition test, while they appear with similar probabilities in the delayed recognition test.
</p>

<p>
Stating the obvious when comparing the two tables: first, the LLM performs immediate recognition faultlessly, while displaying much weaker performance than human subjects on the delayed recognition: lower probability on copy cues, and significantly higher probabilities of false positives (i.e. judging non-copy cues to be included in the list). Second, in the immediate recall task the LLM memory performance is weaker than in the human subject, more so for copy cues than for associate and unrelated cues&#x2013;which seems paradoxical given the perfect match in the recognition task. The LLM, however, siplays an intriguing pattern on the delayed identification task, comparable to human subjects when the cue is an associate word but unable to recall any word in the list when the the cued prompt is a rhyme word. The discussion section looks into the context length and so-called <i>hallucination</i> phenomena as a possible cause for this last observation.
</p>
</div>
</div>

<div id="outline-container-orgff93e1a" class="outline-2">
<h2 id="orgff93e1a">Discussion</h2>
<div class="outline-text-2" id="text-orgff93e1a">
<p>
The LLM &ldquo;Tulving Test&rdquo; rests on the &ldquo;encoding/retrieval paradigm&rdquo; championed bu Tulving. In the paradigm, both encoding and retrieval conditions are experimentally manipulated in order to reveal specificities of each. The results presented in the previous section are part of a program of experiments to explore the relevance of these specificities, as expressed in the GAPS model above, to the current crop of LLMs in Generative AI.
</p>

<p>
In the original direct comparison experiment on human subjects, the effect of copy cues was first discussed. The finding then presented a paradox. The level of of performance with copy cues, i.e. cue words taken from the previously studied list, was generally higher in the familiarity conversion than for the identification conversion (see Table <a href="#org6eb9db7">3</a>). How can the rememberer have difficulty identifying the name of a studied item in the list, when it is the <i>same</i> word which is used in the cue in the recall test, whereas it is asserted as a member of the list in the recognition test? Tulving suggests two possibilities: (i) because of differences in task requirements, the nature of the ecphoric process is different for the two groups of rememberers; and (ii) different types of conversion require different kinds, different amounts, or both of ecphoric information, namely that judgments of identification of a particular aspect of an experienced episode requires ecphoric information of &ldquo;higher quality&rdquo; than judgments that the cue word is familiar. Tulving favored the latter over the former and suggested a theory of <i>conversion thresholds</i> for different kinds of memory tasks.
</p>


<div id="orgf9c3250" class="figure">
<p><img src="sem.png" alt="sem.png" />
</p>
<p><span class="figure-number">Figure 3: </span><b>The Synergistic Ecphory Model (SEM)</b>. Source for figure: Ch.14 <a href="#citeproc_bib_item_1">[1, 14.3]</a>. Schematic diagram depicting a given episode such as the appearance of a familiar word in a particular study list. Variations of trace information, <i>a</i>, <i>b</i> and <i>c</i> correspond to different engrams resulting from many different possible encodings of the same event, only some of which are realized on a particular occasion. Retrieval information <i>x</i>, <i>y</i>, <i>z</i> correspond to the different potentially relevant retrieval cues (recall) that may or may not be present on a particular occasion. (We simplify here under the assumption of a single dimension for memory traces and a single dismension for retrieval information, resulting in a bidimensional ecphoric vector space.) The curved lines represent conversion thresholds for different memory tasks, here recognition/familiarity and recall/identification. According to the position of the point representing the synergy of retrieval and trace information relative to the threshold lines, the rememberer would pass or not the given test.</p>
</div>

<p>
The situation with LLM rememberers is somewhat exacerbated as to the effects of copy cues. Not only the probability of recognition is higher than the same in the human test, but it is a perfect 100%. Furthermore, the probability of recall is lower than the probability of recognition, as for the human rememberer but significantly lower for LLM. So the finding here is even more paradoxical than before: what could explain the performance degradation? Both avenues of investigations are also relevant here. 
</p>

<p>
Recent AI research on prompt engineering <a href="#citeproc_bib_item_9">[9]</a> may point to the first of Tulving&rsquo;s suggestions as a sensible explanation of the aggravated findings for the LLM rememberer. Different structures in the prompts, expressing recognition requests versus recall requests, may indeed entail different ecphoric processes rather than different quantity of information being required <a href="#citeproc_bib_item_10">[10]</a>. On the other hand, the conversion thresholds in the SEM are an attractive alternative as they refer to an ecphoric vector space, which seems cogent to the vector space embedding found in the Transformer architecture (the explanation or the interpretation of which remains crucial for LLM acceptability in general <a href="#citeproc_bib_item_11">[11]</a>).
</p>

<p>
The effects of associative cues (non-copy cues) also call for discussions. Data in Table <a href="#org6eb9db7">3</a> showed a dissociation between the tasks when associative cues were used. Judgments of associative cues as included in the study list (false positives) increased from the immediate to the delayed test, whereas their effectiveness at eliciting the target word, in the recall task, decreased. What Table <a href="#org77d14fe">4</a> first shows is that, even more acutely, the false positives appear only in the chat-based delayed test of recognition, whereas the LLM rememberer failed to pass any chat-based delayed test of identification. In order to quantify the correlation, Tulving introduced the measure of <i>cue valence</i> <a href="#citeproc_bib_item_12">[12]</a> with respect to an aspect of an event or episode refers to the probability with which that aspect of the event can be recalled in the presence of the cue. Table <a href="#org6eb9db7">3</a> allows the quantification of the negative correlation between false positive response rate and the identification valence of associative cues. The SEM above makes also sense here, in explaining out the negative correlation by pinpointing the position in the ecphoric space relative to the conversion threshold curves. In Table <a href="#org77d14fe">4</a> however, the memory performance of the delayed recall tasks appears quite contrasted: a copy cue does not recall a single word of the sudy list, even though the cue is itself that target word! Rhyme cue words fail almost systematically at evoking a target word in the list. Associate cue words, in contrast, trigger comparable, if slightly better, recall performance than in human subjects and unrelated are unrelated.
</p>



<p>
Compare to Estes&rsquo; short/long-term memomy in human and computer discussion <a href="#citeproc_bib_item_13">[13]</a>.
</p>
<blockquote>
<p>
By contrast, the results of research in my laboratory (Estes 1972; Lee and Estes 1977) suggest that human short-term memory is quite differ ently organized, being oriented toward events and their* attributes rather than toward the retention of items as units. In the human memory, forgetting is characteristically a pro gressive loss of precision of informa tion about an event rather than a matter of total recall or total loss of a stored item.
</p>
</blockquote>
</div>
</div>

<div id="outline-container-org20065a0" class="outline-2">
<h2 id="org20065a0">Methods</h2>
<div class="outline-text-2" id="text-org20065a0">
<p>
We transpose the direct comparison experiment, between recognition and recall, described in <a href="#citeproc_bib_item_1">[1, 14]</a> to LLM subjects.
</p>

<p>
Individual experiments are programmed as Python scripts interacting with LLMs through the LLM CLI utility and library <a href="#citeproc_bib_item_14">[14]</a> (Python 3.11.8 on Windows 10). Results presented and discussed in this paper were obtained with <code>mistral-7b-instruct-v0</code> <a href="#citeproc_bib_item_15">[15]</a>. (Results with smaller models, e.g. <code>orca-mini-3b</code> <a href="#citeproc_bib_item_16">[16]</a>, were not reliable enough.)
</p>

<p>
48 simple english words were selected manually to constitute the study list of to-be-remembered words. Firstly, 48 associate cue words were selected from three sources: (i) prompting the LLM for one strongly associated word to each of the 48 to-be-remembered words, (ii) synonyms of each of the 48 words, and (iii) antonyms of each of the 48 words. Antonyms and synonyms were obtained using the Natural Language Toolkit <a href="#citeproc_bib_item_17">[17]</a>. Secondly, 48 rhyme cue words were obtained using the CMU Pronouncing Directory <a href="#citeproc_bib_item_18">[18]</a>. Finally, 16 unrelated english words were picked up manually to act as distractors. The 48-row by 3-column table of target word, associate cue word, rhyme cue words together with the list of 16 distractors is the product of these initial preparation scripts.
</p>

<p>
Each session is made of two tests, one on the recognition task (familiarity), the other on the recall task (identification). Each test lists 32 cue words submitted to the LLM for remembering either (i) if the cue word is included in the study list, for recognition, or (ii) a word in the study list evoked by the cue word, or &ldquo;none&rdquo; (recall). The 32 cue words are grouped into 8 copy cues, 8 associate cues, 8 rhyme cues and 8 unrelated cues. Both the order of the 32 cues and the selection of cue types are randomized before running each session.
</p>

<p>
The recognition and recall 32-word tests are run twice to differentiate immediate from delayed performance. In immediate tests, each individual prompt to the LLM contains the list of 48 words to be remembered before the cue word. In delayed test, each test is a chat beginning with the first instruction to memorize the list of 48 words, preceding a series of individual prompts for each cue word, all within the same chat.
</p>

<p>
Each response of the LLM is analysed and two counts are updated for the presence of the target word in the response, and for the presence of any word in the study list. (Note that the second count deliberately includes false positives in the recognition task with non-copy cues.)
</p>
</div>
</div>

<div id="outline-container-orgcb72c75" class="outline-2">
<h2 id="orgcb72c75">References</h2>
<div class="outline-text-2" id="text-orgcb72c75">
<style>.csl-left-margin{float: left; padding-right: 0em;}
 .csl-right-inline{margin: 0 0 0 2em;}</style><div class="csl-bib-body">
  <div class="csl-entry"><a id="citeproc_bib_item_1"></a>
    <div class="csl-left-margin">[1]</div><div class="csl-right-inline">E. Tulving, <i>Elements of Episodic Memory</i>. Oxford University Press, 1983.</div>
  </div>
  <div class="csl-entry"><a id="citeproc_bib_item_2"></a>
    <div class="csl-left-margin">[2]</div><div class="csl-right-inline">D. L. Schacter, J. E. Eich, and E. Tulving, “Richard Semon’s Theory of Memory,” <i>Journal of Verbal Learning and Verbal Behavior</i>, vol. 17, no. 6, pp. 721–743, 1978, doi: <a href="https://doi.org/https://doi.org/10.1016/S0022-5371(78)90443-7">https://doi.org/10.1016/S0022-5371(78)90443-7</a>.</div>
  </div>
  <div class="csl-entry"><a id="citeproc_bib_item_3"></a>
    <div class="csl-left-margin">[3]</div><div class="csl-right-inline">R. W. Semon, <i>Die Mneme als erhaltendes Prinzip im Wechsel des organischen Geschehens</i>. Engelmann, 1920. doi: <a href="https://doi.org/10.5962/bhl.title.10234">10.5962/bhl.title.10234</a>.</div>
  </div>
  <div class="csl-entry"><a id="citeproc_bib_item_4"></a>
    <div class="csl-left-margin">[4]</div><div class="csl-right-inline">K. S. Lashley, “In Search of the Engram,” 1950.</div>
  </div>
  <div class="csl-entry"><a id="citeproc_bib_item_5"></a>
    <div class="csl-left-margin">[5]</div><div class="csl-right-inline">A. Vaswani <i>et al.</i>, “Attention is all you need,” in <i>Proceedings of the 31st International Conference on Neural Information Processing Systems</i>, in Nips’17. Long Beach, California, USA: Curran Associates Inc., 2017, pp. 6000–6010.</div>
  </div>
  <div class="csl-entry"><a id="citeproc_bib_item_6"></a>
    <div class="csl-left-margin">[6]</div><div class="csl-right-inline">D. Bahdanau, K. Cho, and Y. Bengio, “Neural Machine Translation by Jointly Learning to Align and Translate.”</div>
  </div>
  <div class="csl-entry"><a id="citeproc_bib_item_7"></a>
    <div class="csl-left-margin">[7]</div><div class="csl-right-inline">J. S. Imanol Schlag Kazuki Irie, “Linear Transformers Are Secretly Fast Weight Programmers.”</div>
  </div>
  <div class="csl-entry"><a id="citeproc_bib_item_8"></a>
    <div class="csl-left-margin">[8]</div><div class="csl-right-inline">M. K. Moshe Anisfeld, “Association, Synonymity, and Directionality in False Recognition,” <i>Journal of Experimental Psychology</i>, vol. 77, no. 2, p. 171, 1968, doi: <a href="https://doi.org/10.1037/h0025782">10.1037/h0025782</a>.</div>
  </div>
  <div class="csl-entry"><a id="citeproc_bib_item_9"></a>
    <div class="csl-left-margin">[9]</div><div class="csl-right-inline">J. Wei <i>et al.</i>, “Chain-of-thought prompting elicits reasoning in large language models.” 2023.</div>
  </div>
  <div class="csl-entry"><a id="citeproc_bib_item_10"></a>
    <div class="csl-left-margin">[10]</div><div class="csl-right-inline">J. Li and J. Li, “Memory, Consciousness and Large Language Model.”</div>
  </div>
  <div class="csl-entry"><a id="citeproc_bib_item_11"></a>
    <div class="csl-left-margin">[11]</div><div class="csl-right-inline">G. Tennenholtz <i>et al.</i>, “Demystifying Embedding Spaces using Large Language Models.”</div>
  </div>
  <div class="csl-entry"><a id="citeproc_bib_item_12"></a>
    <div class="csl-left-margin">[12]</div><div class="csl-right-inline">E. Tulving and M. J. Watkins, “Structure Of Memory Traces,” <i>Psychological review</i>, vol. 82, no. 4, pp. 261–275, Jul. 1975, doi: <a href="https://doi.org/10.1037/h0076782">10.1037/h0076782</a>.</div>
  </div>
  <div class="csl-entry"><a id="citeproc_bib_item_13"></a>
    <div class="csl-left-margin">[13]</div><div class="csl-right-inline">W. K. Estes, “Is human memory obsolete?,” <i>Am sci</i>, vol. 68, no. 1, pp. 62–69, Jan. 1980.</div>
  </div>
  <div class="csl-entry"><a id="citeproc_bib_item_14"></a>
    <div class="csl-left-margin">[14]</div><div class="csl-right-inline">S. Willison, “LLM.” https://llm.datasette.io/en/stable/index.html, 2023.</div>
  </div>
  <div class="csl-entry"><a id="citeproc_bib_item_15"></a>
    <div class="csl-left-margin">[15]</div><div class="csl-right-inline">A. Q. Jiang <i>et al.</i>, “Mistral 7B.”</div>
  </div>
  <div class="csl-entry"><a id="citeproc_bib_item_16"></a>
    <div class="csl-left-margin">[16]</div><div class="csl-right-inline">P. Mathur, “An explain tuned OpenLLaMA-3b model on custom wizardlm, alpaca, and dolly datasets,” <i>Github repository, huggingface repository</i>. https://github.com/pankajarm/wizardlm_alpaca_dolly_orca_open_llama_3b, https://https://huggingface.co/psmathur/wizardlm_alpaca_dolly_orca_open_llama_3b; GitHub, HuggingFace, 2023.</div>
  </div>
  <div class="csl-entry"><a id="citeproc_bib_item_17"></a>
    <div class="csl-left-margin">[17]</div><div class="csl-right-inline">S. Bird, E. Klein, and E. Loper, <i>Natural language processing with Python: analyzing text with the Natural Language Toolkit</i>. O’Reilly Media, Inc., 2009.</div>
  </div>
  <div class="csl-entry"><a id="citeproc_bib_item_18"></a>
    <div class="csl-left-margin">[18]</div><div class="csl-right-inline">Carnegie Mellon Speech Group, “The CMU Pronouncing Dictionary.” </div>
  </div>
</div>
</div>
</div>

<div id="outline-container-orgadaaabf" class="outline-2">
<h2 id="orgadaaabf">Acknowledgements</h2>
</div>
<div id="outline-container-org07a8866" class="outline-2">
<h2 id="org07a8866">Author information</h2>
</div>
<div id="outline-container-orga3af8bb" class="outline-2">
<h2 id="orga3af8bb">Ethics declarations</h2>
</div>
<div id="outline-container-org7b24b6f" class="outline-2">
<h2 id="org7b24b6f">Additional information</h2>
</div>
<div id="outline-container-org1eadbae" class="outline-2">
<h2 id="org1eadbae">Electronic supplementary material</h2>
</div>
<div id="outline-container-org97c6ade" class="outline-2">
<h2 id="org97c6ade">Rights and permissions</h2>
</div>
<div id="outline-container-org5903fda" class="outline-2">
<h2 id="org5903fda">Comments</h2>
<div class="outline-text-2" id="text-org5903fda">
<style>
.tippy-box[data-theme~=material]{background-color:#505355;font-weight:600}.tippy-box[data-theme~=material][data-placement^=top]>.tippy-arrow:before{border-top-color:#505355}.tippy-box[data-theme~=material][data-placement^=bottom]>.tippy-arrow:before{border-bottom-color:#505355}.tippy-box[data-theme~=material][data-placement^=left]>.tippy-arrow:before{border-left-color:#505355}.tippy-box[data-theme~=material][data-placement^=right]>.tippy-arrow:before{border-right-color:#505355}.tippy-box[data-theme~=material]>.tippy-backdrop{background-color:#505355}.tippy-box[data-theme~=material]>.tippy-svg-arrow{fill:#505355}
</style>
<script>
tippy('[data-tippy-content]', {
  allowHTML: true,
  theme: 'material',
});
</script>
</div>
</div>
</div>
<div id="postamble" class="status">
<p class="author">Author: J.-M. Chauvet</p>
<p class="date">Created: 2024-02-22 jeu. 19:35</p>
<p class="validation"><a href="https://validator.w3.org/check?uri=referer">Validate</a></p>
</div>
</body>
</html>