<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
"http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en">
<head>
<!-- 2024-02-20 mar. 18:59 -->
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<title>Memory GAPS: Would LLM pass the Tulving Test?</title>
<meta name="author" content="J.-M. Chauvet" />
<meta name="generator" content="Org Mode" />
<style>
  #content { max-width: 60em; margin: auto; }
  .title  { text-align: center;
             margin-bottom: .2em; }
  .subtitle { text-align: center;
              font-size: medium;
              font-weight: bold;
              margin-top:0; }
  .todo   { font-family: monospace; color: red; }
  .done   { font-family: monospace; color: green; }
  .priority { font-family: monospace; color: orange; }
  .tag    { background-color: #eee; font-family: monospace;
            padding: 2px; font-size: 80%; font-weight: normal; }
  .timestamp { color: #bebebe; }
  .timestamp-kwd { color: #5f9ea0; }
  .org-right  { margin-left: auto; margin-right: 0px;  text-align: right; }
  .org-left   { margin-left: 0px;  margin-right: auto; text-align: left; }
  .org-center { margin-left: auto; margin-right: auto; text-align: center; }
  .underline { text-decoration: underline; }
  #postamble p, #preamble p { font-size: 90%; margin: .2em; }
  p.verse { margin-left: 3%; }
  pre {
    border: 1px solid #e6e6e6;
    border-radius: 3px;
    background-color: #f2f2f2;
    padding: 8pt;
    font-family: monospace;
    overflow: auto;
    margin: 1.2em;
  }
  pre.src {
    position: relative;
    overflow: auto;
  }
  pre.src:before {
    display: none;
    position: absolute;
    top: -8px;
    right: 12px;
    padding: 3px;
    color: #555;
    background-color: #f2f2f299;
  }
  pre.src:hover:before { display: inline; margin-top: 14px;}
  /* Languages per Org manual */
  pre.src-asymptote:before { content: 'Asymptote'; }
  pre.src-awk:before { content: 'Awk'; }
  pre.src-authinfo::before { content: 'Authinfo'; }
  pre.src-C:before { content: 'C'; }
  /* pre.src-C++ doesn't work in CSS */
  pre.src-clojure:before { content: 'Clojure'; }
  pre.src-css:before { content: 'CSS'; }
  pre.src-D:before { content: 'D'; }
  pre.src-ditaa:before { content: 'ditaa'; }
  pre.src-dot:before { content: 'Graphviz'; }
  pre.src-calc:before { content: 'Emacs Calc'; }
  pre.src-emacs-lisp:before { content: 'Emacs Lisp'; }
  pre.src-fortran:before { content: 'Fortran'; }
  pre.src-gnuplot:before { content: 'gnuplot'; }
  pre.src-haskell:before { content: 'Haskell'; }
  pre.src-hledger:before { content: 'hledger'; }
  pre.src-java:before { content: 'Java'; }
  pre.src-js:before { content: 'Javascript'; }
  pre.src-latex:before { content: 'LaTeX'; }
  pre.src-ledger:before { content: 'Ledger'; }
  pre.src-lisp:before { content: 'Lisp'; }
  pre.src-lilypond:before { content: 'Lilypond'; }
  pre.src-lua:before { content: 'Lua'; }
  pre.src-matlab:before { content: 'MATLAB'; }
  pre.src-mscgen:before { content: 'Mscgen'; }
  pre.src-ocaml:before { content: 'Objective Caml'; }
  pre.src-octave:before { content: 'Octave'; }
  pre.src-org:before { content: 'Org mode'; }
  pre.src-oz:before { content: 'OZ'; }
  pre.src-plantuml:before { content: 'Plantuml'; }
  pre.src-processing:before { content: 'Processing.js'; }
  pre.src-python:before { content: 'Python'; }
  pre.src-R:before { content: 'R'; }
  pre.src-ruby:before { content: 'Ruby'; }
  pre.src-sass:before { content: 'Sass'; }
  pre.src-scheme:before { content: 'Scheme'; }
  pre.src-screen:before { content: 'Gnu Screen'; }
  pre.src-sed:before { content: 'Sed'; }
  pre.src-sh:before { content: 'shell'; }
  pre.src-sql:before { content: 'SQL'; }
  pre.src-sqlite:before { content: 'SQLite'; }
  /* additional languages in org.el's org-babel-load-languages alist */
  pre.src-forth:before { content: 'Forth'; }
  pre.src-io:before { content: 'IO'; }
  pre.src-J:before { content: 'J'; }
  pre.src-makefile:before { content: 'Makefile'; }
  pre.src-maxima:before { content: 'Maxima'; }
  pre.src-perl:before { content: 'Perl'; }
  pre.src-picolisp:before { content: 'Pico Lisp'; }
  pre.src-scala:before { content: 'Scala'; }
  pre.src-shell:before { content: 'Shell Script'; }
  pre.src-ebnf2ps:before { content: 'ebfn2ps'; }
  /* additional language identifiers per "defun org-babel-execute"
       in ob-*.el */
  pre.src-cpp:before  { content: 'C++'; }
  pre.src-abc:before  { content: 'ABC'; }
  pre.src-coq:before  { content: 'Coq'; }
  pre.src-groovy:before  { content: 'Groovy'; }
  /* additional language identifiers from org-babel-shell-names in
     ob-shell.el: ob-shell is the only babel language using a lambda to put
     the execution function name together. */
  pre.src-bash:before  { content: 'bash'; }
  pre.src-csh:before  { content: 'csh'; }
  pre.src-ash:before  { content: 'ash'; }
  pre.src-dash:before  { content: 'dash'; }
  pre.src-ksh:before  { content: 'ksh'; }
  pre.src-mksh:before  { content: 'mksh'; }
  pre.src-posh:before  { content: 'posh'; }
  /* Additional Emacs modes also supported by the LaTeX listings package */
  pre.src-ada:before { content: 'Ada'; }
  pre.src-asm:before { content: 'Assembler'; }
  pre.src-caml:before { content: 'Caml'; }
  pre.src-delphi:before { content: 'Delphi'; }
  pre.src-html:before { content: 'HTML'; }
  pre.src-idl:before { content: 'IDL'; }
  pre.src-mercury:before { content: 'Mercury'; }
  pre.src-metapost:before { content: 'MetaPost'; }
  pre.src-modula-2:before { content: 'Modula-2'; }
  pre.src-pascal:before { content: 'Pascal'; }
  pre.src-ps:before { content: 'PostScript'; }
  pre.src-prolog:before { content: 'Prolog'; }
  pre.src-simula:before { content: 'Simula'; }
  pre.src-tcl:before { content: 'tcl'; }
  pre.src-tex:before { content: 'TeX'; }
  pre.src-plain-tex:before { content: 'Plain TeX'; }
  pre.src-verilog:before { content: 'Verilog'; }
  pre.src-vhdl:before { content: 'VHDL'; }
  pre.src-xml:before { content: 'XML'; }
  pre.src-nxml:before { content: 'XML'; }
  /* add a generic configuration mode; LaTeX export needs an additional
     (add-to-list 'org-latex-listings-langs '(conf " ")) in .emacs */
  pre.src-conf:before { content: 'Configuration File'; }

  table { border-collapse:collapse; }
  caption.t-above { caption-side: top; }
  caption.t-bottom { caption-side: bottom; }
  td, th { vertical-align:top;  }
  th.org-right  { text-align: center;  }
  th.org-left   { text-align: center;   }
  th.org-center { text-align: center; }
  td.org-right  { text-align: right;  }
  td.org-left   { text-align: left;   }
  td.org-center { text-align: center; }
  dt { font-weight: bold; }
  .footpara { display: inline; }
  .footdef  { margin-bottom: 1em; }
  .figure { padding: 1em; }
  .figure p { text-align: center; }
  .equation-container {
    display: table;
    text-align: center;
    width: 100%;
  }
  .equation {
    vertical-align: middle;
  }
  .equation-label {
    display: table-cell;
    text-align: right;
    vertical-align: middle;
  }
  .inlinetask {
    padding: 10px;
    border: 2px solid gray;
    margin: 10px;
    background: #ffffcc;
  }
  #org-div-home-and-up
   { text-align: right; font-size: 70%; white-space: nowrap; }
  textarea { overflow-x: auto; }
  .linenr { font-size: smaller }
  .code-highlighted { background-color: #ffff00; }
  .org-info-js_info-navigation { border-style: none; }
  #org-info-js_console-label
    { font-size: 10px; font-weight: bold; white-space: nowrap; }
  .org-info-js_search-highlight
    { background-color: #ffff00; color: #000000; font-weight: bold; }
  .org-svg { }
</style>
<script src="https://unpkg.com/@popperjs/core@2"></script>
<script src="https://unpkg.com/tippy.js@6"></script>
<link href="https://fonts.googleapis.com/css?family=EB+Garamond" rel="stylesheet">
<link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/tonsky/FiraCode@4/distr/fira_code.css">
<style>table.ref td{ text-align: right; font-size: small; font-family:'Fira Code', monospace; }</style>
<style>table.center { margin-left:auto; margin-right:auto; }</style>
<style>img.center { margin-left:auto; margin-right:auto; }</style>
<style>.source-code { text-align: left; font-size: small; font-family:'Fira Code', monospace; }</style>
<style>pre { text-align: left; font-size: small; font-family:'Fira Code', monospace; }</style>
<style>body { font-family:'EB Garamond', serif; font-size: 16px; }</style>
<style>blockquote {background: #f9f9f9; border-left: 10px solid #ccc; margin: 1.5em 10px; padding: 0.5em 10px; quotes: "\201C""\201D""\2018""\2019";} blockquote:before {color: #ccc; content: open-quote; font-size: 4em; line-height: 0.1em; margin-right: 0.25em; vertical-align: -0.4em;} blockquote p {display: inline;}</style>
<style>.figure p:nth-child(2) {text-align: justify; text-justify: inter-word;}</style>
<style>table caption {text-align: justify; text-justify: inter-word;}</style>
</head>
<body>
<div id="content" class="content">
<h1 class="title">Memory GAPS: Would LLM pass the Tulving Test?</h1>

<div id="outline-container-orgb013590" class="outline-2">
<h2 id="orgb013590">Abstract</h2>
</div>
<div id="outline-container-orgf6f9097" class="outline-2">
<h2 id="orgf6f9097">Introduction</h2>
<div class="outline-text-2" id="text-orgf6f9097">
<p>
In his groundbreaking studies of memory, Endel Tulving (1927-2023) noted that &ldquo;one of the most compelling and salient characteristics of remembering of past events is the individual&rsquo;s subjective awareness of remembering&rdquo; <a href="#citeproc_bib_item_1">[1]</a>. In order to include the rememberer&rsquo;s recollective experience into the critical constructs in the conceptualization of remembering, Tulving suggested an &ldquo;overall pretheoretical framework&rdquo;, called the <i>General Abstract Processing System</i> or GAPS. This paper investigates whether the GAPS also provides insights when the subject is no longer human but a Large Language Model (LLM).
</p>

<p>
Tulving championed the distinction of <i>episodic</i> from <i>semantic</i> memory, successfully arguing that being functionally different, they represent separate but related systems. Both are placed on the same side of the cognitive division between <i>declarative memory</i> (as episodic and semantic information can be expressed through language&#x2013;e.g. repairing a bicycle) on the one hand, and <i>skills</i> (which can be observed only in behavior&#x2013;e.g. riding a bicycle) on the other.
</p>
</div>

<div id="outline-container-orgb14c694" class="outline-3">
<h3 id="orgb14c694">The GAPS and the Transformer</h3>
<div class="outline-text-3" id="text-orgb14c694">
<p>
In Tulving&rsquo;s framework, a single act of remembering forms the unit of human episodic memory. Remembering is a process that begins with the witnessing or experiencing of an episode and ends with its recollective experience or with the conversion of the remembered information into some other form, or both. The GAPS specifies so called <i>elements</i> of remembering and their interrelations in order to decompose this process.
</p>

<p>
The GAPS distinguishes two kinds of elements: observable events and hypothetical constructs (processes and states); and it divides elements into two categories: elements of encoding and elements of retrieval.
</p>


<div id="org0fa2a65" class="figure">
<p><img src="ElementsOfRemembering-rev.png" alt="ElementsOfRemembering-rev.png" width="500px" />
</p>
<p><span class="figure-number">Figure 1: </span><b>The GAPS: Elements of Episodic Memory and their Relations.</b> The element of encoding is a process that converts the information about an experienced event or episode (in a particular setting, at a particular time) into an <i>engram</i> or memory trace. The central element of the retrieval processes <i>ecphoric</i> information, a synergistic product of the engram and the retrieval cue, which calls on both episodic and semantic information. Source for figure: Ch. 7, <a href="#citeproc_bib_item_1">[1, 7-1, p. 135]</a>.</p>
</div>

<p>
Of particular interest to this study of applicability of the GAPS framework to LLM are the possible transpositions of engram and ecphoric information into the domain of generative AI. In his seminal book, Tulving offers a very broad definition of engrams: &ldquo;the product of encoding&rdquo;, &ldquo;conditions for recollection of the experienced event&rdquo;, or &ldquo;differences between the state of the memory system before and after encoding&rdquo;. The latter is closely related the original definitions of these terms introduced by Richard Semon (1859&#x2013;1918): &ldquo;to represent the enduring changes brought about by the energetic effect of stimuli in the organism&rdquo; <a href="#citeproc_bib_item_2">[2]</a>, <a href="#citeproc_bib_item_3">[3]</a>. Note that if, in both clarifications, the nature of the changes are unknown, the term became nonetheless broadly known in psychology research through the later work of Karl Lashley (1890&#x2013;1958) concluding, amongst other experimental results on neural mechanisms involved in learning and memory, that &ldquo;there is no demonstrable localization of memory trace&rdquo; <a href="#citeproc_bib_item_4">[4]</a>.
</p>

<p>
Similarly inspired by Semon, Tulving suggested the terms <i>ecphory</i> and <i>ecphoric information</i> to designate respectively the process that brings (i) the relevant information in the retrieval environment into interaction with (ii) the original or recoded engram, and the output of this process. Such ecphoric information determines the particulars of recollective experience in the next phase of remembering: <i>conversion</i>. In the GAPS model, ecphoric information is basically a task-free component of the retrieval process, it is simply used by being converted into another form in the memory performance.
</p>

<p>
The categories of encoding and retrieval in the GAPS are not without analogies with the <i>Transformer</i> architecture of neural networks at the core of LLMs, which precisely articulates encoders and decoders to process vector embeddings representing words and sentences.
</p>


<div id="org7779346" class="figure">
<p><img src="Transformer.png" alt="Transformer.png" width="500px" />
</p>
<p><span class="figure-number">Figure 2: </span><b>The Transformer Architecture.</b> Based on the 2017 paper <a href="#citeproc_bib_item_5">[5]</a> attention mechanism, the Transformer architecture requires less training time than previous recurrent neural architectures. Input text is split into tokens (sometimes called <i>n-gram</i>, dangerously reminiscent of Semon&rsquo;s engrams&#x2013;see text), then converted into vectors. Through different layers, each token is contextualized with other tokens via parallel attention heads, calculating weights for each according to its importance. The Transformer Architecture elaborates on <i>softmax-based</i> attention mechanism <a href="#citeproc_bib_item_6">[6]</a> and <i>Fast Weight Controllers</i> <a href="#citeproc_bib_item_7">[7]</a>. Source for figure: <a href="#citeproc_bib_item_5">[5]</a>.</p>
</div>

<p>
At this stage, from cursorily reviewing the architecture of both GAPS and Transformer&#x2013;and keeping in mind that Tulving&rsquo;s psychological framework is only &ldquo;pre-theoretical&rdquo; and &ldquo;highly schematic&rdquo;, while Transformers are actual computer implementations&#x2013;the practical analogy would unfold as follows:
</p>

<table id="org6143b2b" border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">
<caption class="t-above"><span class="table-number">Table 1:</span> <b>Hypothetical analogy between GAPS and Transformer.</b> Semantic memory, in Tulving&rsquo;s acception, would be represented by the probability distribution learned by the LLM during the pretraining phase. In Transformers it determines the particulars of the output based on the input (prompt).</caption>

<colgroup>
<col  class="org-left" />

<col  class="org-left" />

<col  class="org-left" />
</colgroup>
<thead>
<tr>
<th scope="col" class="org-left">&#xa0;</th>
<th scope="col" class="org-left">GAPS</th>
<th scope="col" class="org-left">Transformer</th>
</tr>
</thead>
<tbody>
<tr>
<td class="org-left">Processes</td>
<td class="org-left">encoding</td>
<td class="org-left">encoder</td>
</tr>

<tr>
<td class="org-left">&#xa0;</td>
<td class="org-left">recoding</td>
<td class="org-left">encoder</td>
</tr>

<tr>
<td class="org-left">&#xa0;</td>
<td class="org-left">ecphory</td>
<td class="org-left">encoder</td>
</tr>

<tr>
<td class="org-left">&#xa0;</td>
<td class="org-left">conversion</td>
<td class="org-left">decoder</td>
</tr>
</tbody>
<tbody>
<tr>
<td class="org-left">States</td>
<td class="org-left">engram</td>
<td class="org-left">vector embedding</td>
</tr>

<tr>
<td class="org-left">&#xa0;</td>
<td class="org-left">ecphoric information</td>
<td class="org-left">output probabilities</td>
</tr>

<tr>
<td class="org-left">&#xa0;</td>
<td class="org-left">memory performance</td>
<td class="org-left">output</td>
</tr>
</tbody>
</table>
</div>
</div>

<div id="outline-container-orgdfb04d3" class="outline-3">
<h3 id="orgdfb04d3">Tulving&rsquo;s &ldquo;direct comparison&rdquo;: recognition versus recall</h3>
<div class="outline-text-3" id="text-orgdfb04d3">
<p>
In order to further investigate the analogy and its grounds, we adopt Tulving&rsquo;s design of &ldquo;direct comparison&rdquo; experiments to assess recognition versus recall tasks in LLMs. Recognition and recall are both processes of retrieval and both result in the rememberer&rsquo;s awareness of a past event. The simple episodes in the experiment are to be presentations of a list of English words to be remembered. In this simplified situation of comparing recognition and recall tasks, we consider only two independent dimensions: one has to do with the type of retrieval information, or <i>cue</i>, available to the rememberer; the second refers to the conversion process in the GAPS framework. The retrieval information includes copies of the studied words and non-copy cue words. As for the conversion process: in the recognition task, the rememberer has to express whether or not the cue word was in the study list (<i>familiarity</i>); in the recall task, the rememberer has to identify a word in the study list, if any, associated with the cue word (<i>identification</i>), thereby expressing some other aspect of the original memorizing experience. Note that in the GAPS framework, the first dimension involves processes anterior to the construction of ecphoric information, while the second relates to post-ecphoric processes. The experimental results are therefore captured by the 2 x 2 matrix in Table <a href="#orga5e4168">2</a>
</p>

<table id="orga5e4168" border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">
<caption class="t-above"><span class="table-number">Table 2:</span> Differences between recognition and recall tasks. Source for table: Ch. <a href="#citeproc_bib_item_1">[1, p. 14]</a>.</caption>

<colgroup>
<col  class="org-left" />

<col  class="org-left" />

<col  class="org-left" />
</colgroup>
<thead>
<tr>
<th scope="col" class="org-left">Retrieval information</th>
<th scope="col" class="org-left">Conversion</th>
<th scope="col" class="org-left">&#xa0;</th>
</tr>

<tr>
<th scope="col" class="org-left">&#xa0;</th>
<th scope="col" class="org-left">Familiarity</th>
<th scope="col" class="org-left">Identification</th>
</tr>
</thead>
<tbody>
<tr>
<td class="org-left">Copy Cue Word</td>
<td class="org-left"><i>Recognition</i></td>
<td class="org-left"><i>?</i></td>
</tr>

<tr>
<td class="org-left">Non-Copy Cue Word</td>
<td class="org-left"><i>?</i></td>
<td class="org-left"><i>Recall</i></td>
</tr>
</tbody>
</table>

<p>
Conventional recognition and recall tests sit in two of the four cells in the matrix. When the rememberer, however, declares a cue other than a copy cue word to be familiar it is a <i>false positive</i> response from the conventional perspective although psychologists might disagree on how to think about such responses <a href="#citeproc_bib_item_8">[8]</a>. The other empty cell represents a situation where the rememberer&rsquo;s somewhat strange task is to repeat the cue word to confirm it is associated with the copy in the study list. <i>False negatives</i> are of interest here and Tulving&rsquo;s interpretation was that these entailed a form of continuity between recognition and recall retrieval processes.
</p>

<p>
The direct comparison test design represents all four cells of the matrix. In a typical session the LLM is prompted to memorize a list of 48 common english words. In a group of experiments, the LLM is prompted with a cue word and asked whether the cue is included or not in the studied list; in another group, the LLM is prompted with a cue word and asked to retrieve any strongly associated word in the studied list (or none if no such word is evoked by the cue).
</p>

<p>
In each experiment 32 cue words are presented in the 32 prompts: eight of these cue words were identical with eight words in the list (<i>copy cues</i>), eight were strongly associated words (<i>non-copy associated</i> cues), eight were rhyming words (<i>non copy rhymes</i> cues), and eight were unrelated distractors (<i>non-copy unrelated</i> cues). The 32 cue words are identical for both the recognition and the recall task.
</p>

<p>
In order to introduce the distinction between immediate and delayed retrieval of the original experimental design, the experiment is run twice for each group: in the first run, memorization and retrieval are both in each individual prompt (immediate); in the second, memorization is the first prompt of a conversation (chat) with the LLM, followed by retrieval prompts which continue the conversation (delayed).
</p>
</div>
</div>
</div>

<div id="outline-container-orgb049299" class="outline-2">
<h2 id="orgb049299">Results</h2>
<div class="outline-text-2" id="text-orgb049299">
<p>
As a reference benchmark, the results of Tulving&rsquo;s original experiments are presented in Table <a href="#orgb346251">3</a> from Ch. <a href="#citeproc_bib_item_1">[1, p. 14, Table 14.2]</a>:
</p>

<table id="orgb346251" border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">
<caption class="t-above"><span class="table-number">Table 3:</span> <b>Summary of memory performance in the original direct comparison experiment.</b> Each proportion shown is based on 576 observations. The data for the familiarity (recognition) task show proportion of cases in which the human subjects regarder the cue word as included in the list. Hence the data for copy cues represent &rsquo;correct&rsquo; responses, whereas the data from the other three types of cues represent &rsquo;false positives&rsquo;. The data for the indetification (recall) task indicate proportions of responses to the cue being any target word in the list.</caption>

<colgroup>
<col  class="org-left" />
</colgroup>

<colgroup>
<col  class="org-right" />

<col  class="org-right" />
</colgroup>

<colgroup>
<col  class="org-right" />

<col  class="org-right" />
</colgroup>
<thead>
<tr>
<th scope="col" class="org-left">Retrieval information</th>
<th scope="col" class="org-right">Conversion</th>
<th scope="col" class="org-right">&#xa0;</th>
<th scope="col" class="org-right">&#xa0;</th>
<th scope="col" class="org-right">&#xa0;</th>
</tr>

<tr>
<th scope="col" class="org-left">&#xa0;</th>
<th scope="col" class="org-right">Familiarity</th>
<th scope="col" class="org-right">&#xa0;</th>
<th scope="col" class="org-right">Identification</th>
<th scope="col" class="org-right">&#xa0;</th>
</tr>

<tr>
<th scope="col" class="org-left">&#xa0;</th>
<th scope="col" class="org-right">Immediate</th>
<th scope="col" class="org-right">Delayed</th>
<th scope="col" class="org-right">Immediate</th>
<th scope="col" class="org-right">Delayed</th>
</tr>
</thead>
<tbody>
<tr>
<td class="org-left">Copy Cue Word</td>
<td class="org-right">0.78</td>
<td class="org-right">0.71</td>
<td class="org-right">0.69</td>
<td class="org-right">0.60</td>
</tr>

<tr>
<td class="org-left">Non-Copy Associated</td>
<td class="org-right">0.15</td>
<td class="org-right">0.20</td>
<td class="org-right">0.54</td>
<td class="org-right">0.37</td>
</tr>

<tr>
<td class="org-left">Non-copy Rhyme</td>
<td class="org-right">0.09</td>
<td class="org-right">0.15</td>
<td class="org-right">0.20</td>
<td class="org-right">0.31</td>
</tr>

<tr>
<td class="org-left">Non-copy Unrelated</td>
<td class="org-right">0.08</td>
<td class="org-right">0.18</td>
<td class="org-right">0.04</td>
<td class="org-right">0.02</td>
</tr>
</tbody>
</table>


<p>
The memory performance of LLMs in the Tulving Test of direct comparison is presented along the same format in Table <a href="#org410d4d3">4</a>.
</p>

<table id="org410d4d3" border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">
<caption class="t-above"><span class="table-number">Table 4:</span> <b>Summary of memory performance of the <code>mistral-7b-instruct-v0</code> LLM in the direct comparison experiment.</b> Each proportion is based on 384 observations (but see text). Interpretations of proportions are the same as above Table <a href="#orgb346251">3</a>.</caption>

<colgroup>
<col  class="org-left" />
</colgroup>

<colgroup>
<col  class="org-right" />

<col  class="org-right" />
</colgroup>

<colgroup>
<col  class="org-right" />

<col  class="org-right" />
</colgroup>
<thead>
<tr>
<th scope="col" class="org-left">Retrieval information</th>
<th scope="col" class="org-right">Conversion</th>
<th scope="col" class="org-right">&#xa0;</th>
<th scope="col" class="org-right">&#xa0;</th>
<th scope="col" class="org-right">&#xa0;</th>
</tr>

<tr>
<th scope="col" class="org-left">&#xa0;</th>
<th scope="col" class="org-right">Familiarity</th>
<th scope="col" class="org-right">&#xa0;</th>
<th scope="col" class="org-right">Identification</th>
<th scope="col" class="org-right">&#xa0;</th>
</tr>

<tr>
<th scope="col" class="org-left">&#xa0;</th>
<th scope="col" class="org-right">Immediate</th>
<th scope="col" class="org-right">Delayed</th>
<th scope="col" class="org-right">Immediate</th>
<th scope="col" class="org-right">Delayed</th>
</tr>
</thead>
<tbody>
<tr>
<td class="org-left">Copy Cue Word</td>
<td class="org-right">1</td>
<td class="org-right">0.46</td>
<td class="org-right">0.46</td>
<td class="org-right">0</td>
</tr>

<tr>
<td class="org-left">Non-Copy Associated</td>
<td class="org-right">0</td>
<td class="org-right">0.47</td>
<td class="org-right">0.49</td>
<td class="org-right">0</td>
</tr>

<tr>
<td class="org-left">Non-copy Rhyme</td>
<td class="org-right">0</td>
<td class="org-right">0.50</td>
<td class="org-right">0.18</td>
<td class="org-right">0</td>
</tr>

<tr>
<td class="org-left">Non-copy Unrelated</td>
<td class="org-right">0</td>
<td class="org-right">0.41</td>
<td class="org-right">0.08</td>
<td class="org-right">0</td>
</tr>
</tbody>
</table>

<p>
Within each result table, several comparisons are of interest. First the probability that copy cues were familiar was higher than the probability of identification and production of the target word in response to the copy cue, in both the human (Table <a href="#orgb346251">3</a>) and the  LLM (Table <a href="#org410d4d3">4</a>) subject&#x2013;here <code>mistral-7b-instruct-v0</code>. Second, the probability that extra-list unrelated cues were (incorrectly) recognized as members of the memorized list increased from the immediate to delayed test, in both human and LLM subjects. Remarkably and contrasting with the human subject, in the immediate recognition task the LLM never erred: no false positives for non-copy cues and 100% familiarity for copy cues. Third, rhyme words proved in both cases more effective than unrelated distractor cues in recall. Fourth, strongly associated cues were considered members of the list with much higher probability in the immediate test, the difference being greatly reduced in the delayed test. The case of the LLM subject varies a bit, since no false positives are produced in the immediate recognition test, while they appear with similar probabilities in the delayed recognition test.
</p>

<p>
Stating the obvious when comparing the two tables: firts, the LLM performs immediate recognition faultlessly, while displaying much weaker performance than the human subject on the delayed recognition: lower probability on copy cues, and significantly higher probabilities of false positives (judging non copy cues to be included in the list). Second, in the immediate recall task the LLM memory performance is weaker than in the human subject, more so for copy cues than for associate and unrelated cues&#x2013;which seems paradoxical given the perfect match in the recognition task. The LLM, however, fails miserably on the delayed identification task, unable to recall any word in the list whatever the cued prompt. The discussion section looks into the context length and so-called <i>hallucination</i> phenomena as a possible cause for this last observation.
</p>
</div>
</div>


<div id="outline-container-org21c15ad" class="outline-2">
<h2 id="org21c15ad">Discussion</h2>
<div class="outline-text-2" id="text-org21c15ad">
<p>
Compare to Estes&rsquo; short/long-term memomy in human and computer discussion <a href="#citeproc_bib_item_9">[9]</a>.
</p>
<blockquote>
<p>
By contrast, the results of research in my laboratory (Estes 1972; Lee and Estes 1977) suggest that human short-term memory is quite differ ently organized, being oriented toward events and their* attributes rather than toward the retention of items as units. In the human memory, forgetting is characteristically a pro gressive loss of precision of informa tion about an event rather than a matter of total recall or total loss of a stored item.
</p>
</blockquote>
</div>
</div>

<div id="outline-container-orgc3e643e" class="outline-2">
<h2 id="orgc3e643e">Methods</h2>
<div class="outline-text-2" id="text-orgc3e643e">
<p>
We transpose the direct comparison experiment, between recognition and recall, described in <a href="#citeproc_bib_item_1">[1, 14]</a> to LLM subjects.
</p>

<p>
Individual experiments are programmed as Python scripts interacting with LLMs through the LLM CLI utility and library <a href="#citeproc_bib_item_10">[10]</a> (Python 3.11.8 on Windows 10). Results presented and discussed in this paper were obtained with <code>mistral-7b-instruct-v0</code> <a href="#citeproc_bib_item_11">[11]</a>. (Results with smaller models, e.g. <code>orca-mini-3b</code> <a href="#citeproc_bib_item_12">[12]</a>, were not reliable enough.)
</p>

<p>
48 simple english words were selected manually to constitute the study list of to-be-remembered words. Firstly, 48 associate cue words were selected from three sources: (i) prompting the LLM for one strongly associated word to each of the 48 to-be-remembered words, (ii) synonyms of each of the 48 words, and (iii) antonyms of each of the 48 words. Antonyms and synonyms were obtained using the Natural Language Toolkit <a href="#citeproc_bib_item_13">[13]</a>. Secondly, 48 rhyme cue words were obtained using the CMU Pronouncing Directory <a href="#citeproc_bib_item_14">[14]</a>. Finally, 16 unrelated english words were picked up manually to act as distractors. The 48-row by 3-column table of target word, associate cue word, rhyme cue words together with the list of 16 distractors is the product of these initial preparation scripts.
</p>

<p>
Each session is made of two tests, one on the recognition task (familiarity), the other on the recall task (identification). Each test lists 32 cue words submitted to the LLM for remembering either (i) if the cue word is included in the study list, for recognition, or (ii) a word in the study list evoked by the cue word, or &ldquo;none&rdquo; (recall). The 32 cue words are grouped into 8 copy cues, 8 associate cues, 8 rhyme cues and 8 unrelated cues. Both the order of the 32 cues and the selection of cue types are randomized before running each session.
</p>

<p>
The recognition and recall 32-word tests are run twice to differentiate immediate from delayed performance. In immediate tests, each individual prompt to the LLM contains the list of 48 words to be remembered before the cue word. In delayed test, each test is a chat beginning with the first instruction to memorize the list of 48 words, preceding a series of individual prompts for each cue word, all within the same chat.
</p>

<p>
Each response of the LLM is analysed and two counts are updated for the presence of the target word in the response, and for the presence of any word in the study list. (Note that the second count deliberately includes false positives in the recognition task with non-copy cues.)
</p>
</div>
</div>




<div id="outline-container-org5e2b008" class="outline-2">
<h2 id="org5e2b008">References</h2>
<div class="outline-text-2" id="text-org5e2b008">
<style>.csl-left-margin{float: left; padding-right: 0em;}
 .csl-right-inline{margin: 0 0 0 2em;}</style><div class="csl-bib-body">
  <div class="csl-entry"><a id="citeproc_bib_item_1"></a>
    <div class="csl-left-margin">[1]</div><div class="csl-right-inline">E. Tulving, <i>Elements of Episodic Memory</i>. Oxford University Press, 1983.</div>
  </div>
  <div class="csl-entry"><a id="citeproc_bib_item_2"></a>
    <div class="csl-left-margin">[2]</div><div class="csl-right-inline">D. L. Schacter, J. E. Eich, and E. Tulving, “Richard Semon’s Theory of Memory,” <i>Journal of verbal learning and verbal behavior</i>, vol. 17, no. 6, pp. 721–743, 1978, doi: <a href="https://doi.org/https://doi.org/10.1016/S0022-5371(78)90443-7">https://doi.org/10.1016/S0022-5371(78)90443-7</a>.</div>
  </div>
  <div class="csl-entry"><a id="citeproc_bib_item_3"></a>
    <div class="csl-left-margin">[3]</div><div class="csl-right-inline">R. W. Semon, <i>Die Mneme als erhaltendes Prinzip im Wechsel des organischen Geschehens</i>. Engelmann, 1920. doi: <a href="https://doi.org/10.5962/bhl.title.10234">10.5962/bhl.title.10234</a>.</div>
  </div>
  <div class="csl-entry"><a id="citeproc_bib_item_4"></a>
    <div class="csl-left-margin">[4]</div><div class="csl-right-inline">K. S. Lashley, “In Search of the Engram,” 1950.</div>
  </div>
  <div class="csl-entry"><a id="citeproc_bib_item_5"></a>
    <div class="csl-left-margin">[5]</div><div class="csl-right-inline">A. Vaswani <i>et al.</i>, “Attention is all you need,” in <i>Proceedings of the 31st international conference on neural information processing systems</i>, in Nips’17. Long Beach, California, USA: Curran Associates Inc., 2017, pp. 6000–6010.</div>
  </div>
  <div class="csl-entry"><a id="citeproc_bib_item_6"></a>
    <div class="csl-left-margin">[6]</div><div class="csl-right-inline">D. Bahdanau, K. Cho, and Y. Bengio, “Neural Machine Translation by Jointly Learning to Align and Translate.”</div>
  </div>
  <div class="csl-entry"><a id="citeproc_bib_item_7"></a>
    <div class="csl-left-margin">[7]</div><div class="csl-right-inline">J. S. Imanol Schlag Kazuki Irie, “Linear Transformers Are Secretly Fast Weight Programmers.”</div>
  </div>
  <div class="csl-entry"><a id="citeproc_bib_item_8"></a>
    <div class="csl-left-margin">[8]</div><div class="csl-right-inline">M. K. Moshe Anisfeld, “Association, Synonymity, and Directionality in False Recognition,” <i>Journal of experimental psychology</i>, vol. 77, no. 2, p. 171, 1968, doi: <a href="https://doi.org/10.1037/h0025782">10.1037/h0025782</a>.</div>
  </div>
  <div class="csl-entry"><a id="citeproc_bib_item_9"></a>
    <div class="csl-left-margin">[9]</div><div class="csl-right-inline">W. K. Estes, “Is human memory obsolete?,” <i>Am sci</i>, vol. 68, no. 1, pp. 62–69, Jan. 1980.</div>
  </div>
  <div class="csl-entry"><a id="citeproc_bib_item_10"></a>
    <div class="csl-left-margin">[10]</div><div class="csl-right-inline">S. Willison, “LLM.” https://llm.datasette.io/en/stable/index.html, 2023.</div>
  </div>
  <div class="csl-entry"><a id="citeproc_bib_item_11"></a>
    <div class="csl-left-margin">[11]</div><div class="csl-right-inline">A. Q. Jiang <i>et al.</i>, “Mistral 7B.”</div>
  </div>
  <div class="csl-entry"><a id="citeproc_bib_item_12"></a>
    <div class="csl-left-margin">[12]</div><div class="csl-right-inline">P. Mathur, “An explain tuned OpenLLaMA-3b model on custom wizardlm, alpaca, and dolly datasets,” <i>Github repository, huggingface repository</i>. https://github.com/pankajarm/wizardlm_alpaca_dolly_orca_open_llama_3b, https://https://huggingface.co/psmathur/wizardlm_alpaca_dolly_orca_open_llama_3b; GitHub, HuggingFace, 2023.</div>
  </div>
  <div class="csl-entry"><a id="citeproc_bib_item_13"></a>
    <div class="csl-left-margin">[13]</div><div class="csl-right-inline">S. Bird, E. Klein, and E. Loper, <i>Natural language processing with Python: analyzing text with the Natural Language Toolkit</i>. O’Reilly Media, Inc., 2009.</div>
  </div>
  <div class="csl-entry"><a id="citeproc_bib_item_14"></a>
    <div class="csl-left-margin">[14]</div><div class="csl-right-inline">Carnegie Mellon Speech Group, “The CMU Pronouncing Dictionary.” </div>
  </div>
</div>
</div>
</div>

<div id="outline-container-org3305a44" class="outline-2">
<h2 id="org3305a44">Acknowledgements</h2>
</div>
<div id="outline-container-org8929a04" class="outline-2">
<h2 id="org8929a04">Author information</h2>
</div>
<div id="outline-container-orgca7f4d6" class="outline-2">
<h2 id="orgca7f4d6">Ethics declarations</h2>
</div>
<div id="outline-container-org173fd3a" class="outline-2">
<h2 id="org173fd3a">Additional information</h2>
</div>
<div id="outline-container-org290240a" class="outline-2">
<h2 id="org290240a">Electronic supplementary material</h2>
</div>
<div id="outline-container-orgcfc9abf" class="outline-2">
<h2 id="orgcfc9abf">Rights and permissions</h2>
</div>
<div id="outline-container-orge5690a4" class="outline-2">
<h2 id="orge5690a4">About this article</h2>
</div>
<div id="outline-container-orgc1c176b" class="outline-2">
<h2 id="orgc1c176b">Further reading</h2>
</div>
<div id="outline-container-org7126d38" class="outline-2">
<h2 id="org7126d38">Comments</h2>
<div class="outline-text-2" id="text-org7126d38">
<style>
.tippy-box[data-theme~=material]{background-color:#505355;font-weight:600}.tippy-box[data-theme~=material][data-placement^=top]>.tippy-arrow:before{border-top-color:#505355}.tippy-box[data-theme~=material][data-placement^=bottom]>.tippy-arrow:before{border-bottom-color:#505355}.tippy-box[data-theme~=material][data-placement^=left]>.tippy-arrow:before{border-left-color:#505355}.tippy-box[data-theme~=material][data-placement^=right]>.tippy-arrow:before{border-right-color:#505355}.tippy-box[data-theme~=material]>.tippy-backdrop{background-color:#505355}.tippy-box[data-theme~=material]>.tippy-svg-arrow{fill:#505355}
</style>
<script>
tippy('[data-tippy-content]', {
  allowHTML: true,
  theme: 'material',
});
</script>
</div>
</div>
</div>
<div id="postamble" class="status">
<p class="author">Author: J.-M. Chauvet</p>
<p class="date">Created: 2024-02-20 mar. 18:59</p>
<p class="validation"><a href="https://validator.w3.org/check?uri=referer">Validate</a></p>
</div>
</body>
</html>